# S3 Buckets
* Amazon S3 allows people to store objects (files) fun “buckets” (directories); can create folders under bucket. 
* Highly available and highly durable
* Buckets must have a globally unique name; similar to DNS address. 
    * Naming convention:
        * No uppercase
        * No underscore
        * 3-63 characters long
        * Not an IP
        * Must start with lowercase letter or number
* Objects
    * Objects (files) have a Key. The key is the name of object:
        * <my_bucket>/my_file.txt
        * <my_bucket>/my_folder/another_folder/my_file.txt
    * There’s no concept of “directories” within buckets (although the UI will trick you to think otherwise)
    * Just keys with very long names that contain slashes (“/“)
    * Object Values are the content of the body:
        * Max Size is 5TB; unlimited storage
        * If uploading more than 5GB, must use “multi-part upload”
    * Metadata (list of text key / value pairs - system or user metadata; data about the data you are storing)
    * Tags (Unicode key / value pair - up to 10) - useful for security / lifecycle
    * Version ID (important for storing multiple versions of the same object)
    * Value: this is the data itself, which is made up of a sequence of bytes. 
    * Cannot use to run operating system or database.

#### AWS S3 - Versioning
* By default: bucket versioning is disable
* It is enabled at the bucket level
* Same key overwrite will increment the “version”: 1, 2, 3
* It is best practice to version your buckets
    * Protect against unintended deletes (ability to restore a version)
    * Easy roll back to previous versions
* Any file that is not version prior to enabling versioning will have the version “null”

#### S3 Encryption for Objects
* There are 4 methods of encrypt objects in S3
    * Server-Side encryption: set default encryption on a bucket to encrypt all new objectes when they are stored in the bucket.By default - disable.
       * SSE-S3: encrypts S3 objects
           * Encryption using keys handled & managed by AWS S3
           * Object is encrypted server side
           * AES-256 encryption type
           * Must set header: “x-amz-server-side-encryption”:”AES256”
       * SSE-KMS (key management service): encryption using keys handled & managed by KMS
           * KMS Advantages: user control + audit trail
           * Object is encrypted server side
           * Maintain control of the rotation policy for the encryption keys
           * Must set header: “x-amz-server-side-encryption”:”aws:kms”
       * SSE-C: server-side encryption using data keys fully managed by the customer outside of AWS
           * Amazon S3 does not store the encryption key you provide
           * HTTPS must be used
           * Encryption key must provided in HTTP headers, for every HTTP request made
    * Client Side Encryption
        * Client library such as the amazon S3 Encryption Client
        * Clients must encrypt data themselves before sending to S3
        * Clients must decrypt data themselves when retrieving from S3
        * Customer fully manages the keys and encryption cycle

#### Encryption in transit (SSL)
* AWS S3 exposes:
    * HTTP endpoint: non encrypted
    * HTTPS endpoint: encryption in flight
* You’re free to use the endpoint your ant, but HTTPS is recommended
* HTTPS is mandatory for SSE-C
* Encryption in flight is also called SSL / TLS

#### S3 Security
* User based
    * IAM policies - which API calls should be allowed for a specific user from IAM console
* Resource based
    * Bucket policies - bucket wide rules from the S3 console - allows cross account
       * applied to bucket levels, not individual objects. 
       * Written in Json. 
       * Bucket policy override the object policy. 
    * Access Control List(ACLs): define which AWS accounts or groups are granted access and the type of access. You can attach S3 ACLs to individual objects within a bucket.
       * Object Access Control List (ACL) - finer grain
       * Bucket Access Control List (ACL) - less common
         * By default: block all public access; 
    * Object lock: store objects using a write-once-read-many(WORM) model to help you prevent objects from being deleted or overwritten for a fixed amount of time or indefinitely.
* Networking
    * Support VPC endpoints (for instances in VPC without www internet)
* Logging and Audit:
    * S3 access logs can be stored in other S3 buckets
      * will log all requests made to the S3 bucket
      * not by default; can be configured to create access logs
    * API calls can be logged in AWS CloudTrail
* User Security:
* MFA (multi factor authentication) can be required in versioned buckets to delete objects
* Signed URLs: URLS that are valid only for a limited time (ex: premium video services for logged in users)

#### S3 Bucket Policies
- Which actions are allowed or denied? 
* JSON based policies
    * Resources: buckets and objects
    * Actions: Set of API to Allow or Deny
    * Effect: Allow / Deny
    * Principal: The account or user to apply the policy to
* Use S3 bucket for policy to:
    * Grant public access to the bucket
    * Force objects to be encrypted at upload
    * Grant access to another account (Cross Account)

#### S3 Websites
* S3 can host static website sand have them accessible on the world wide web
* The website URL will be:
    * <bucket-name>.s3-website.<AWS-region>.amzonaws.com/<Object-Name>
    * OR
    * <bucket-name>.s3-website.<AWS-region>.amazonaws.com/<Object-Name>
* If you get a 403 (forbidden) error, make sure the bucket policy allows public reads!

#### S3 Cors
* If you request data from another S3 bucket, you need to enable CORS
* Cross Origin Resource Sharing allows you to limit the number of websites that can request your files in S3 (and limit your costs)
* This is a popular exam question

#### AWS S3 - Consistency Model
* Read after write consistency for PUTS of new objects
    * As soon as an object is written, we can retrieve itex: (PUT 200 -> GET 200)
    * This is true, except if we did a GET before to see if the object existed
    
    ex: (GET 404 -> PUT 200 -> GET 404) - eventually consistent
* Eventual Consistency for DELETES and PUTS of existing objects
    * If we read an object after updating, we might get the older version
    
    ex: (PUT 200 -> PUT 200 -> GET 200 (might be older version))
    * If we delete an object, we might still be able to retrieve it for a short time
    
    ex: (DELETE 200 -> GET 200)

#### AWS S3 - Other
* S3 can send notifications on changes to
    * AWS SQS: queue service
    * AWS SNS: notification service
    * AWS Lambda: serverless service
* S3 has a cross region replication feature (managed)

#### AWS S3 Performance
* Faster upload of large objects (>5GB), use multipart upload
    * Parallelizes PUTs for greater throughput
    * Maximize your network bandwidth
    * Decrease time to retry in case a part fails
* Use CloudFront to ache S3 objects around the world (improves reads)
* S3 Transfer Acceleration (uses edge locations) - just need to change the endpoint you write to, not the code
* If using SSE-KMS encryption, you may be limited to your AWS limits for KMS usage (~100s - 1000s downloads / uploads per second)

   
#### Tiered Storage
- After uploading objects, we could choose to enable versioning/encryption/ACLs/Object lock and choose different storage class. 
* S3 Standard
   * high available and high durability
      * data is store redundantly (across at least 3 AZs)
   * designed for frequent accesss
   * use case: website, content distribution, mobile, gaming
*  S3 standard-infrequent access (S3-IA)
   * Rapid access; less frequently
   * Pay to access the data
   * use case: long term storgae, backups, disaster recovery files; minimum storage duration: 30 days.
* S3 one zone-infrequently access
   * 20% less; only within a single AZs
   * use case: non critical data
* Glacier: cheap storgae; infrequently used
   * Glacier: long term data; 90s day minimum storage
   * Glacier Deep Archive: rarely accessed data; 180 days minimum storage duration
* S3 Intelligent Tiering: sometimes frequently, sometimes infrequently; optimizes cost
* Cost order: S3 standard > S3 Intelligent > other tiers (retrieval fee applies)
   
#### Lifecycle management

   
   
 
